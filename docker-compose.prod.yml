# Fabstir LLM Node Production Docker Compose
# Copyright (c) 2025 Fabstir
# SPDX-License-Identifier: BUSL-1.1
#
# Usage:
#   1. Copy .env.prod.example to .env.prod and configure
#   2. docker-compose -f docker-compose.prod.yml up -d
#
# Required environment variables (in .env.prod):
#   - S5_SEED_PHRASE: S5 identity seed phrase for storage uploads
#   - HOST_PRIVATE_KEY: Host wallet private key for settlements
#

services:
  # S5 Bridge - Must start first for storage uploads
  s5-bridge:
    build:
      context: ./services/s5-bridge
      dockerfile: Dockerfile
    container_name: s5-bridge
    restart: unless-stopped
    env_file:
      - .env
    environment:
      BRIDGE_PORT: 5522
      BRIDGE_HOST: 0.0.0.0
      S5_SEED_PHRASE: ${S5_SEED_PHRASE:?S5_SEED_PHRASE is required}
      S5_PORTAL_URL: ${S5_PORTAL_URL:-https://s5.platformlessai.ai}
      S5_INITIAL_PEERS: ${S5_INITIAL_PEERS:-wss://z2Das8aEF7oNoxkcrfvzerZ1iBPWfm6D7gy3hVE4ALGSpVB@node.sfive.net/s5/p2p,wss://z2DWuWNZcdSyZLpXFK2uCU3haaWMXrDAgxzv17sDEMHstZb@s5.garden/s5/p2p,wss://z2Dh2pH1t1u3mjoQKDrZccLQ1CG9hJe3wdFvLCQhDx5UX1K@s5.vup.cx/s5/p2p}
      HOST_PRIVATE_KEY: ${HOST_PRIVATE_KEY}
      LOG_LEVEL: ${LOG_LEVEL:-info}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5522/health"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3
    networks:
      - fabstir-network

  # Fabstir LLM Node - Main inference service
  llm-node:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: llm-node-prod
    restart: unless-stopped
    runtime: nvidia
    env_file:
      - .env
    ports:
      - "${API_PORT:-8080}:${API_PORT:-8080}"      # API port
      - "${P2P_PORT:-9000}:${P2P_PORT:-9000}"      # P2P port
      - "9001:9001"      # P2P port
      - "9002:9002"      # P2P port
    environment:
      # NVIDIA GPU
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility

      # S5 Storage - connects to s5-bridge service
      ENHANCED_S5_URL: http://s5-bridge:5522

      # Model configuration
      MODEL_PATH: ${MODEL_PATH:-/app/models/openai_gpt-oss-20b-MXFP4.gguf}
      LLAMA_BATCH_SIZE: ${LLAMA_BATCH_SIZE:-2048}

      # Network configuration
      P2P_PORT: ${P2P_PORT:-9000}
      API_PORT: ${API_PORT:-8080}

      # Blockchain configuration
      HOST_PRIVATE_KEY: ${HOST_PRIVATE_KEY}
      CHAIN_ID: ${CHAIN_ID:-84532}
      RPC_URL: ${RPC_URL}

      # Contract addresses (AUDIT-F4 compliant - Feb 2026)
      CONTRACT_NODE_REGISTRY: ${CONTRACT_NODE_REGISTRY:-0x8BC0Af4aAa2dfb99699B1A24bA85E507de10Fd22}
      CONTRACT_JOB_MARKETPLACE: ${CONTRACT_JOB_MARKETPLACE:-0x95132177F964FF053C1E874b53CF74d819618E06}
      CONTRACT_PROOF_SYSTEM: ${CONTRACT_PROOF_SYSTEM:-0xE8DCa89e1588bbbdc4F7D5F78263632B35401B31}
      CONTRACT_HOST_EARNINGS: ${CONTRACT_HOST_EARNINGS:-0xE4F33e9e132E60fc3477509f99b9E1340b91Aee0}
      CONTRACT_MODEL_REGISTRY: ${CONTRACT_MODEL_REGISTRY:-0x1a9d91521c85bD252Ac848806Ff5096bBb9ACDb2}

      # Model validation (v8.14.0+) - set to true to enforce
      REQUIRE_MODEL_VALIDATION: ${REQUIRE_MODEL_VALIDATION:-false}

      # Logging
      RUST_LOG: ${RUST_LOG:-info}

      # Optional: Web search
      WEB_SEARCH_ENABLED: ${WEB_SEARCH_ENABLED:-true}
      BRAVE_API_KEY: ${BRAVE_API_KEY:-}

      # Optional: VLM Vision sidecar (for high-VRAM hosts)
      VLM_ENDPOINT: ${VLM_ENDPOINT:-http://qwen3-vl:8081}
      VLM_MODEL_NAME: ${VLM_MODEL_NAME:-qwen3-vl}

    volumes:
      # Mount model directory
      - ${MODELS_DIR:-./models}:/app/models:ro
      # Mount pre-built binary (from tarball)
      - ./target/release/fabstir-llm-node:/usr/local/bin/fabstir-llm-node:ro
    depends_on:
      s5-bridge:
        condition: service_healthy
    networks:
      - fabstir-network

  # VLM Vision Sidecar (optional - for high-VRAM hosts only)
  # Requires ~5GB VRAM for Qwen3-VL-8B-Instruct Q4_K_M
  # To disable: set VLM_ENDPOINT= (empty) in .env or stop this service
  # First build: docker-compose -f docker-compose.prod.yml build qwen3-vl
  qwen3-vl:
    build:
      context: .
      dockerfile: docker/Dockerfile.vlm-sidecar
    container_name: qwen3-vl
    restart: unless-stopped
    runtime: nvidia
    environment:
      NVIDIA_VISIBLE_DEVICES: all
    volumes:
      - ${VLM_MODEL_PATH:-./models/qwen3-vl}:/models:ro
    command: >
      --model /models/${VLM_MODEL_FILE:-Qwen3VL-8B-Instruct-Q4_K_M.gguf}
      --mmproj /models/${VLM_MMPROJ_FILE:-mmproj-Qwen3VL-8B-Instruct-F16.gguf}
      --host 0.0.0.0 --port 8081
      --ctx-size 4096 --n-gpu-layers 99
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      start_period: 120s
      retries: 3
    networks:
      - fabstir-network

networks:
  fabstir-network:
    name: fabstir-network
    driver: bridge
